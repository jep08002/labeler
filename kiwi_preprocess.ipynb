{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "845fe4d3-20cb-4b37-95ad-12867bd25706",
   "metadata": {},
   "source": [
    "# Move all .txt files to a common folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "18075dd9-513b-4497-bd9f-5b7410c79484",
   "metadata": {},
   "outputs": [
    {
     "ename": "SameFileError",
     "evalue": "'A:/Projects/CXR Reports\\\\Reports\\\\s50000014.txt' and 'A:/Projects/CXR Reports/Reports\\\\s50000014.txt' are the same file",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mSameFileError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 13\u001b[0m\n\u001b[0;32m     11\u001b[0m             src_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(root, file)\n\u001b[0;32m     12\u001b[0m             dest_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(destination_dir, file)\n\u001b[1;32m---> 13\u001b[0m             \u001b[43mshutil\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcopy2\u001b[49m\u001b[43m(\u001b[49m\u001b[43msrc_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdest_path\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# copy2 preserves metadata\u001b[39;00m\n\u001b[0;32m     15\u001b[0m total_files \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m([f \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m os\u001b[38;5;241m.\u001b[39mlistdir(destination_dir) \u001b[38;5;28;01mif\u001b[39;00m f\u001b[38;5;241m.\u001b[39mlower()\u001b[38;5;241m.\u001b[39mendswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.txt\u001b[39m\u001b[38;5;124m\"\u001b[39m)])\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDone! All \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtotal_files\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m .txt files copied.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\envs\\ards_env\\lib\\shutil.py:434\u001b[0m, in \u001b[0;36mcopy2\u001b[1;34m(src, dst, follow_symlinks)\u001b[0m\n\u001b[0;32m    432\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39misdir(dst):\n\u001b[0;32m    433\u001b[0m     dst \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(dst, os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mbasename(src))\n\u001b[1;32m--> 434\u001b[0m \u001b[43mcopyfile\u001b[49m\u001b[43m(\u001b[49m\u001b[43msrc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdst\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfollow_symlinks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfollow_symlinks\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    435\u001b[0m copystat(src, dst, follow_symlinks\u001b[38;5;241m=\u001b[39mfollow_symlinks)\n\u001b[0;32m    436\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m dst\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\envs\\ards_env\\lib\\shutil.py:234\u001b[0m, in \u001b[0;36mcopyfile\u001b[1;34m(src, dst, follow_symlinks)\u001b[0m\n\u001b[0;32m    231\u001b[0m sys\u001b[38;5;241m.\u001b[39maudit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshutil.copyfile\u001b[39m\u001b[38;5;124m\"\u001b[39m, src, dst)\n\u001b[0;32m    233\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _samefile(src, dst):\n\u001b[1;32m--> 234\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m SameFileError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{!r}\u001b[39;00m\u001b[38;5;124m and \u001b[39m\u001b[38;5;132;01m{!r}\u001b[39;00m\u001b[38;5;124m are the same file\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(src, dst))\n\u001b[0;32m    236\u001b[0m file_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m    237\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, fn \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m([src, dst]):\n",
      "\u001b[1;31mSameFileError\u001b[0m: 'A:/Projects/CXR Reports\\\\Reports\\\\s50000014.txt' and 'A:/Projects/CXR Reports/Reports\\\\s50000014.txt' are the same file"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "base_dir = r\"A:/Projects/CXR Reports\"       # Folder where the search starts\n",
    "destination_dir = r\"A:/Projects/CXR Reports/Reports\"  # Folder where .txt files will be copied\n",
    "\n",
    "# iterate through all files in base directory\n",
    "for root, dirs, files in os.walk(base_dir):\n",
    "    for file in files:\n",
    "        if file.lower().endswith(\".txt\") and not file.startswith(\".\"):\n",
    "            src_path = os.path.join(root, file)\n",
    "            dest_path = os.path.join(destination_dir, file)\n",
    "            shutil.copy2(src_path, dest_path)  # copy2 preserves metadata\n",
    "\n",
    "total_files = len([f for f in os.listdir(destination_dir) if f.lower().endswith(\".txt\")])\n",
    "print(f\"Done! All {total_files} .txt files copied.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b116b6a9-1d37-468d-a0c9-2691dfea4715",
   "metadata": {},
   "source": [
    "# Process all .txt files to strip extraneous information leaving just impressions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0b359038-bc93-4010-9e67-9ac2dfb329f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed .txt files: 1001\n",
      "Wrote stripped files: 999\n",
      "Skipped (all stripped out): 1\n",
      "Output folder: A:/Projects/CXR Reports/Reports_Stripped\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "\n",
    "base_dir = r\"A:/Projects/CXR Reports/Reports\"\n",
    "output_dir = r\"A:/Projects/CXR Reports/Reports_Stripped\"\n",
    "max_files = 1000\n",
    "\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Keep these \n",
    "KEEP_HEADERS = {\"FINDINGS\", \"IMPRESSION\", \"IMPRESSIONS\"}  # normalize later\n",
    "\n",
    "# Remove these (unwanted)\n",
    "UNWANTED_HEADERS = [\n",
    "    \"INDICATION FOR EXAM\",\n",
    "    \"CLINICAL HISTORY\",\n",
    "    \"FINAL REPORT\",\n",
    "    \"HISTORY\",\n",
    "    \"TECHNIQUE\",\n",
    "    \"COMPARISON\",\n",
    "    \"INDICATION\",\n",
    "    \"EXAM\",\n",
    "    \"EXAMINATION\",\n",
    "    \"REASON FOR EXAM\",\n",
    "    \"REASON FOR EXAMINATION\",\n",
    "    \"WET READ\",\n",
    "    \"NOTIFICAION\"\n",
    "]\n",
    "\n",
    "# Build a robust alternation that favors longer matches first\n",
    "UNWANTED_HEADERS.sort(key=len, reverse=True)\n",
    "UNWANTED_ALT = \"|\".join(re.escape(h) for h in UNWANTED_HEADERS)\n",
    "\n",
    "# Any header: ALL-CAPS-ish with allowed punctuation, *must* be followed by a colon\n",
    "ANY_HEADER_RE = re.compile(\n",
    "    r'^\\s*[A-Z][A-Z0-9\\s/()&\\-\\.\\+]{2,}\\s*:',\n",
    "    flags=re.IGNORECASE | re.MULTILINE\n",
    ")\n",
    "\n",
    "REMOVE_RE = re.compile(\n",
    "    rf'^\\s*(?:{UNWANTED_ALT})\\s*:\\s*.*?'\n",
    "    r'(?=^\\s*[A-Z][A-Z0-9\\s/()&\\-\\.\\+]{2,}\\s*:|\\Z)',\n",
    "    flags=re.IGNORECASE | re.DOTALL | re.MULTILINE\n",
    ")\n",
    "\n",
    "def normalize(text: str) -> str:\n",
    "    # Normalize line endings; leave only \\n internally\n",
    "    return text.replace('\\r\\n', '\\n').replace('\\r', '\\n')\n",
    "\n",
    "def drop_preamble_before_first_header(text: str) -> str:\n",
    "    m = ANY_HEADER_RE.search(text)\n",
    "    if not m:\n",
    "        return text  # no headers detected; return as-is\n",
    "    return text[m.start():]  # drop everything before first header\n",
    "\n",
    "def collapse_blank_lines(text: str) -> str:\n",
    "    lines = [ln.rstrip() for ln in text.split('\\n')]\n",
    "    out = []\n",
    "    blank = False\n",
    "    for ln in lines:\n",
    "        if ln.strip() == \"\":\n",
    "            if not blank:\n",
    "                out.append(\"\")\n",
    "            blank = True\n",
    "        else:\n",
    "            out.append(ln)\n",
    "            blank = False\n",
    "    return \"\\n\".join(out).strip()\n",
    "\n",
    "def strip_unwanted_sections(text: str) -> str:\n",
    "    text = normalize(text)\n",
    "    text = drop_preamble_before_first_header(text)\n",
    "    text = REMOVE_RE.sub('', text)\n",
    "    text = collapse_blank_lines(text)\n",
    "    return text\n",
    "\n",
    "processed = kept_any = skipped = 0\n",
    "limit_hit = False\n",
    "\n",
    "for root, _, files in os.walk(base_dir):\n",
    "    for fname in files:\n",
    "        if not fname.lower().endswith(\".txt\"):\n",
    "            continue\n",
    "        processed += 1\n",
    "        if processed > max_files:\n",
    "            limit_hit = True\n",
    "            break\n",
    "\n",
    "        src_path = os.path.join(root, fname)\n",
    "        try:\n",
    "            with open(src_path, \"r\", encoding=\"utf-8\", errors=\"ignore\") as f:\n",
    "                text = f.read()\n",
    "        except Exception as e:\n",
    "            print(f\"Could not read {src_path}: {e}\")\n",
    "            continue\n",
    "\n",
    "        cleaned = strip_unwanted_sections(text)\n",
    "\n",
    "        if cleaned:\n",
    "            kept_any += 1\n",
    "            final_text = re.sub(r'[\\r\\n]+', ' ', cleaned)  # replace any run of \\r or \\n with a space\n",
    "            final_text = re.sub(r'\\s{2,}', ' ', final_text).strip()  # collapse double spaces\n",
    "            final_text = re.sub(r'\\b(?:IMPRESSION|FINAL REPORT|FINDINGS)\\b\\s*:?\\s*','', final_text, flags=re.IGNORECASE).strip()\n",
    "            out_path = os.path.join(output_dir, fname)\n",
    "            try:\n",
    "                with open(out_path, \"w\", encoding=\"utf-8\", newline=\"\\r\\n\") as f:\n",
    "                    f.write(final_text)\n",
    "            except Exception as e:\n",
    "                print(f\"Could not write {out_path}: {e}\")\n",
    "        else:\n",
    "            skipped += 1\n",
    "\n",
    "print(f\"Processed .txt files: {processed}\")\n",
    "print(f\"Wrote stripped files: {kept_any}\")\n",
    "print(f\"Skipped (all stripped out): {skipped}\")\n",
    "print(f\"Output folder: {output_dir}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c650a4b8-b3bc-4091-a3ab-8fbc627abd06",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
